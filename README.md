# learning-archive
keeping tab of all the stuff, that i learnt today, the source might be youtube, sites, anything, that catches my attemtion

<details>
<summary>25th April</summary>
  <br>
  
Youtube Video, about chatGPT jailbreak [link](https://www.youtube.com/watch?v=zn2ukSnDqSg)
1. LLMs, are predictive models, where, their primary job is, to predict what you would say next, in order to continue the conversation. Like, if we are talking about chess, then it will also continue coversing about it, and might say about moves in chess, prominent people etc. however, it won't "know" anything about it.
2. Just because, LLM's response seems spooky, doesn't mean its able to reason. Far from it, its just able to mimic it.
3. There comes its limitations. Well, there are ethics and rules in place, as to what all ChatGPT can say...
4. The authoer, shows an example, that, how it could "hack" its way, into giving relevent tweets, about flat earth being real.
5. However, my personal opinion, is, it wasn't very impressive to me. So I thought, of taking up a notch... Because, I felt, flat earth, wasn't a sensative topic... you know what's sensative ? Encouraging Pornography. <a href="https://github.com/abhideepd/learning-archive/files/15122857/ChatGPT.pdf">pdf of my chats for jailbreaking</a> 
6. Prompt injection, which, primarily, is aimed at chatbots, that are being used as customer service etc. with certain prompts, we can "hack" our way, to break their terms and conditions. 
7. A popular method, the professors use, now a days, to catch hold of chatgpt plagerism.
</details>

<details>
<summary>26th April</summary>
 <br>
<details>
  
<summary>
  self compiling compilers
</summary>
   <br>
Youtube video, about Self compiling compilers <a href="https://www.youtube.com/watch?v=lJf2i87jgFA&ab_channel=Computerphile">link</a> <br>
1. Well, I have always been fascinated by compilers in general, this shit, just spirals my mind <br>
2. I kind of find compilers to be like black magic, devian art. <br>
3. Okay, starting about the notes, for this video below: <br>
4. Surprisingly, the concept is not new, used everywhere. <br>
5. The compiler written assembly, might have a very very hidden bug, that might crash everything. <br>
6. These bugs, we can never be sure, where it is, because, it will escape all the generic test cases… <br>
7. Can we use, a not top quality thing, to make a better instance of itself ? See, this idea is not new, just wait…. <br>
8. Look at the machine tool industry, they have been doing this for ages, using, not very good tools, to make some tool sharper and better, like almost blunt blades, are used to polish other blades, to make it sharper and better. <br>
9. "eathing yourself to make a better version of yourself" <br>
10. So suppose, there is an existing  compiler, written in assembly, which turns a c program to binary, of suppose binary version a (BVA) <br>
11. I want to make a better binary file, which is more optimized and efficient. So what I do is, write this compiler in C, which generates Binary B which is better (BVB - binary version B). However, where do I run this compiler C ? Into the previous compiler which is written in assembly! <br>
12. So, when we run the 2nd compiler, in the previous step, we get a better binary than, we were getting in the compiler in step 10! <br>
13. The only weakness is, its still running on Binary A ultimately, making it, like a bit slow…. <br>
14. Well, create a new executable, in the new complier which takes BVB and converts to C program, so, what happens, now, is we don't need BVA anymore….. <br>
15. This all sounds spooky and mind twisting man, inception, tenet and intersteller was not enough for this, lol! <br>
Well, to be honest, at the end of the video, stuff went over my head, I could blast my brains out to learn what they are saying, however, I feel, why don't I make a compiler, as I haven't ever done it, this might clear these stuff out…

</details>

<details>
  <summary>
    AI Chips
  </summary>
Watched some other youtube videos about AI, heard about Groq AI chip, which using opensource llms and propriotary small llms to increase their speed in multiple of 10's xs. I didn't understand however, how are they better than nvidea, a quick google search revealed, these two have different approaches towards speeding llms, I think, a little depth is required in order to understand what they are talking about.
<a href="https://www.youtube.com/watch?v=pRUddK6sxDg&ab_channel=Groq">link to the groq ai video</a>
</details>

</details>

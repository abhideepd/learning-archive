# learning-archive
keeping tab of all the stuff, that i learnt today, the source might be youtube, sites, anything, that catches my attemtion

## 26th April
Youtube Video, about chatGPT jailbreak [link](https://www.youtube.com/watch?v=zn2ukSnDqSg)
1. LLMs, are predictive models, where, their primary job is, to predict what you would say next, in order to continue the conversation. Like, if we are talking about chess, then it will also continue coversing about it, and might say about moves in chess, prominent people etc. however, it won't "know" anything about it.
2. Just because, LLM's response seems spooky, doesn't mean its able to reason. Far from it, its just able to mimic it.
3. There comes its limitations. Well, there are ethics and rules in place, as to what all ChatGPT can say...
4. The authoer, shows an example, that, how it could "hack" its way, into giving relevent tweets, about flat earth being real.
5. However, my personal opinion, is, it wasn't very impressive to me. So I thought, of taking up a notch... Because, I felt, flat earth, wasn't a sensative topic... you know what's sensative ? Encouraging Pornography. Here is the below conversation....
  
  <details>
    <summary>my chats for jailbreaking</summary>
    [ChatGPT.pdf](https://github.com/abhideepd/learning-archive/files/15122857/ChatGPT.pdf)
  </details>
  
6. Prompt injection, which, primarily, is aimed at chatbots, that are being used as customer service etc. with certain prompts, we can "hack" our way, to break their terms and conditions. 
7. A popular method, the professors use, now a days, to catch hold of chatgpt plagerism.

## 27th April
